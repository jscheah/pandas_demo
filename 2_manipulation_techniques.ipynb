{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31e1eaea",
   "metadata": {},
   "source": [
    "# Manipulation Techniques\n",
    "\n",
    "## Combining Data\n",
    "\n",
    "There are 3 main ways for combining pandas data frames\n",
    "\n",
    "1. Concatenate\n",
    "2. Merge\n",
    "3. Join\n",
    "\n",
    "#### todo: Add graphic on concatenate vs merge vs join here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf7397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup default imports here\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Example on concatenation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd8c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example on Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Example on Join"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "2be89525",
   "metadata": {},
   "source": [
    "#### Subtle differences (Merge vs Join)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56751118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filtering Data\n",
    "Filtering in Pandas involves selecting specific rows or columns from a DataFrame based on certain conditions. There are 2 main ways to filter data in Pandas,\n",
    "1. conditional statements / boolean indexing\n",
    "2. query expressions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "data = {'Name': ['John', 'Jane', 'Alice'],\n",
    "        'Age': [25, 30, 28],\n",
    "        'Salary': [50000, 60000, 55000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where age is greater than 25"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. Conditional statements / Boolean Indexing\n",
    "filtered_df = df[df['Age'] > 25]\n",
    "\n",
    "# What is happening?\n",
    "print(filtered_df)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5881ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Filter rows using a query expression\n",
    "filtered_df = df.query('Age > 25')\n",
    "\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad6d4ec",
   "metadata": {},
   "source": [
    "### Comparison\n",
    "When it comes to performance differences between conditional statements and query expressions in Pandas, it depends on the specific use case and the complexity of the condition being applied.\n",
    "\n",
    "In general, query expressions can provide faster performance for large DataFrames compared to conditional statements. This is because query expressions leverage underlying code optimizations and evaluation strategies implemented by Pandas. Query expressions are compiled and optimized, which allows for more efficient execution of the filtering operation.\n",
    "\n",
    "On the other hand, conditional statements are more flexible and allow for more complex conditions and logical expressions. They can handle a wider range of conditions and provide more explicit control over the filtering process.\n",
    "\n",
    "It's important to note that the performance difference between query expressions and conditional statements may not be significant for small DataFrames or simple conditions. The impact becomes more noticeable as the size of the DataFrame and the complexity of the condition increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71803f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance example\n",
    "# Create a large DataFrame with random values\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame({\n",
    "    'A': np.random.randint(0, 1000, 10 ** 7),\n",
    "    'B': np.random.randint(0, 1000, 10 ** 7),\n",
    "    'C': np.random.randint(0, 1000, 10 ** 7),\n",
    "    'D': np.random.randint(0, 1000, 10 ** 7),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Using query expression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%timeit\n",
    "conditional_filtered = df[(df['A'] > 500) & (df['B'] < 500)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%timeit\n",
    "query_filtered = df.query('A > 500 and B < 500')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conditional_filtered"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query_filtered"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GroupBy / Aggregation Data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Name': ['John', 'Jane', 'John', 'Alice', 'Jane'],\n",
    "    'Age': [25, 30, 28, 32, 27],\n",
    "    'Salary': [50000, 60000, 55000, 70000, 65000]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T13:22:41.149501800Z",
     "start_time": "2023-05-23T13:22:41.133878400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\n",
      "Alice    70000.0\n",
      "Jane     62500.0\n",
      "John     52500.0\n",
      "Name: Salary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Basic grouping with aggregation\n",
    "# Group by 'Name' and calculate the average salary\n",
    "grouped_df = df.groupby('Name')['Salary'].mean()\n",
    "\n",
    "print(grouped_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T13:22:53.462172700Z",
     "start_time": "2023-05-23T13:22:53.430249200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Salary  Age\n",
      "Name  Age              \n",
      "Alice 32   70000.0   32\n",
      "Jane  27   65000.0   27\n",
      "      30   60000.0   30\n",
      "John  25   50000.0   25\n",
      "      28   55000.0   28\n"
     ]
    }
   ],
   "source": [
    "# Grouping with Multiple Columns and Aggregations:\n",
    "# Group by 'Name' and 'Age', calculate the average salary and maximum age\n",
    "grouped_df = df.groupby(['Name', 'Age']).agg({'Salary': 'mean', 'Age': 'max'})\n",
    "print(grouped_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T13:22:47.563676100Z",
     "start_time": "2023-05-23T13:22:47.554272300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Salary\n",
      "Name         \n",
      "Alice       0\n",
      "Jane     5000\n",
      "John     5000\n"
     ]
    }
   ],
   "source": [
    "# Grouping with Custom Aggregation Functions:\n",
    "# Define a custom aggregation function\n",
    "def salary_range(series):\n",
    "    return series.max() - series.min()\n",
    "\n",
    "\n",
    "# Group by 'Name' and calculate the salary range using the custom function\n",
    "grouped_df = df.groupby('Name').agg({'Salary': salary_range})\n",
    "print(grouped_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T13:48:09.406654100Z",
     "start_time": "2023-05-23T13:48:09.391032900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reshaping Data\n",
    "Reshaping data in Pandas involves transforming the structure of a DataFrame to make it more suitable for analysis or presentation. There are several functions in Pandas that can be used for reshaping data.\n",
    "\n",
    "### Long to Wide\n",
    "pivot(): The pivot() function allows you to reshape a DataFrame based on unique values in one or more columns. It creates a new DataFrame with columns derived from the unique values and reshapes the data accordingly. Used most commonly to reshape data from long to wide format\n",
    "\n",
    "### Wide to Long\n",
    "melt(): The melt() function is used to unpivot or melt a DataFrame, transforming it from a wide format to a long format.\n",
    "It gathers multiple columns into key-value pairs, creating a new DataFrame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Given data below how would you extract it?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Given the same data but in wide format, how would you go about transforming it to wide format\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The choice between wide format and long format depends on the specific circumstances and the type of analysis or presentation you want to perform. Here are some considerations to help you decide:\n",
    "\n",
    "Wide Format:\n",
    "Suitable when we have a small number of variables and want to display data in a compact and easily readable format.\n",
    "Convenient for data entry or manual editing, as each variable has its own column.\n",
    "Useful when performing operations that require calculations across multiple variables.\n",
    "Commonly used for exporting data to other software or systems that expect a wide format.\n",
    "Long Format:\n",
    "\n",
    "Suitable when we have a large number of variables or variable categories, and you want to store and analyze them more efficiently.\n",
    "Enables easy expansion of the dataset by adding new categories or variables.\n",
    "Ideal for performing aggregations, transformations, and analysis using groupby, pivot, or melt operations.\n",
    "Facilitates easier merging and joining of datasets with different variables or categories.\n",
    "Often preferred for visualization purposes, as it allows for flexible plotting and faceting.\n",
    "\n",
    "In summary, the wide format is advantageous when the focus is on a compact representation of data or when working with a small number of variables. On the other hand, the long format is more flexible for analysis, transformation, and visualization, especially when dealing with a large number of variables or when the dataset structure may evolve over time."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
